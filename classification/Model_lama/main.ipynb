{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call data.fif\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "raw = mne.io.read_raw_fif('data.fif', preload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, events_id = mne.events_from_annotations(raw)\n",
    "print(events_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.filter(.5, 30., fir_design='firwin')\n",
    "\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False,\n",
    "                       exclude='bads')\n",
    "\n",
    "\n",
    "tmin, tmax = 0, 2\n",
    "event_id = dict({'fist': 1, 'hook': 2, 'index': 3, 'open': 4, 'thumb': 5})\n",
    "\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs['fist'].average()\n",
    "print(evoked)\n",
    "evoked.plot(time_unit='s')\n",
    "\n",
    "evoked = epochs['hook'].average()\n",
    "print(evoked)\n",
    "evoked.plot(time_unit='s')\n",
    "\n",
    "evoked = epochs['index'].average()\n",
    "print(evoked)\n",
    "evoked.plot(time_unit='s')\n",
    "\n",
    "evoked = epochs['open'].average()\n",
    "print(evoked)\n",
    "evoked.plot(time_unit='s')\n",
    "\n",
    "evoked = epochs['thumb'].average()\n",
    "print(evoked)\n",
    "evoked.plot(time_unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting labels and changing labels from 7,8,9,10 -> 1,2,3,4\n",
    "labels = epochs.events[:,-1]\n",
    "data = epochs.get_data()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "# signal is decomposed to level 5 with 'db4' wavelet\n",
    "\n",
    "def wpd(X): \n",
    "    coeffs = pywt.WaveletPacket(X,'db4',mode='symmetric',maxlevel=5)\n",
    "    return coeffs\n",
    "             \n",
    "def feature_bands(x):\n",
    "    \n",
    "    Bands = np.empty((8,x.shape[0],x.shape[1],38)) # 8 freq band coefficients are chosen from the range 4-32Hz\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for ii in range(x.shape[1]):\n",
    "             pos = []\n",
    "             C = wpd(x[i,ii,:]) \n",
    "             pos = np.append(pos,[node.path for node in C.get_level(5, 'natural')])\n",
    "             for b in range(1,9):\n",
    "                 Bands[b-1,i,ii,:] = C[pos[b]].data\n",
    "        \n",
    "    return Bands\n",
    "\n",
    "wpd_data = feature_bands(data)\n",
    "print(wpd_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import CSP \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "# OneHotEncoding Labels\n",
    "enc = OneHotEncoder()\n",
    "X_out = enc.fit_transform(labels.reshape(-1,1)).toarray()\n",
    "print(X_out)\n",
    "# Cross Validation Split\n",
    "cv = ShuffleSplit(n_splits = 10, test_size = 0.2, random_state = 0)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mne.decoding import CSP\n",
    "\n",
    "svms = []\n",
    "Csp = [CSP(n_components=4, reg=None, log=True, norm_trace=False) for _ in range(8)]\n",
    "Csp = [Csp[x].fit(wpd_data[x,...],labels) for x  in range(8)]\n",
    "ss = preprocessing.StandardScaler()\n",
    "ss = ss.fit(np.concatenate(tuple(Csp[x].transform(wpd_data[x, ...]) for x  in range(8)),axis=-1))\n",
    "\n",
    "acc = []\n",
    "ka = []\n",
    "prec = []\n",
    "recall = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels):\n",
    "    \n",
    "    label_train, label_test = labels[train_idx], labels[test_idx]\n",
    "    y_train, y_test = X_out[train_idx], X_out[test_idx]\n",
    "    \n",
    "    # Extraction features \n",
    "    X_train = ss.transform(np.concatenate(tuple(Csp[x].transform(wpd_data[x,train_idx,:,:]) for x  in range(8)),axis=-1))\n",
    "\n",
    "    X_test = ss.transform(np.concatenate(tuple(Csp[x].transform(wpd_data[x,test_idx,:,:]) for x  in range(8)),axis=-1))\n",
    "    \n",
    "    # Build and train SVM classifier\n",
    "    svm = SVC(kernel='linear', C=1, probability=True)\n",
    "    svm.fit(X_train, label_train)\n",
    "\n",
    "    svms.append(svm)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = svm.predict(X_test)\n",
    "    y_prob = svm.predict_proba(X_test)\n",
    "    \n",
    "    pred = (y_prob == y_prob.max(axis=1)[:, None]).astype(int)\n",
    "    \n",
    "    # Calculate and store metrics\n",
    "    acc.append(accuracy_score(label_test, y_pred))\n",
    "    ka.append(cohen_kappa_score(label_test, y_pred))\n",
    "    prec.append(precision_score(label_test, y_pred, average='weighted'))\n",
    "    recall.append(recall_score(label_test, y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores = {'Accuracy':acc,'Kappa':ka,'Precision':prec,'Recall':recall}\n",
    "\n",
    "Es = pd.DataFrame(scores)\n",
    "\n",
    "avg = {'Accuracy':[np.mean(acc)],'Kappa':[np.mean(ka)],'Precision':[np.mean(prec)],'Recall':[np.mean(recall)]}\n",
    "\n",
    "Avg = pd.DataFrame(avg)\n",
    "\n",
    "\n",
    "T = pd.concat([Es,Avg])\n",
    "\n",
    "T.index = ['F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','Avg']\n",
    "T.index.rename('Fold',inplace=True)\n",
    "\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
